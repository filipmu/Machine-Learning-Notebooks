{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A DSL alongside a Genetic Algorithm applied to the ARC Dataset - Run version\n",
    "\n",
    "In this notebook, we present a minimalistic *Domain Specific Language* for some ARC tasks. We also implement an evaluation function able to run a such program against an input image.\n",
    "\n",
    "In a second time, we implement a simple genetic algorithm that is able to generate programs written in this DSL and demonstrate its usage on an ARC task.\n",
    "\n",
    "!!begin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additions\n",
    "\n",
    "* Added function to increase size of images - provides ability to representation on a 90x90 grid providing space around the image\n",
    "* Additional scratchpad in the image - hidden colors on top of existing to indicate awareness of patterns to next operators - can be used for identifying filling, size/rank of objects, boundaries, special pixels, other features - this may not be necessary, since operators create multiple images, and other operators combine them.\n",
    "* create operators "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import operator\n",
    "## see https://stackoverflow.com/questions/952914/how-to-make-a-flat-list-out-of-list-of-lists\n",
    "def list_flatten(a):\n",
    "    return functools.reduce(operator.iconcat, a, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import random\n",
    "\n",
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "\n",
    "import ast\n",
    "import re \n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "\n",
    "#data_path = Path('/kaggle/input/abstraction-and-reasoning-challenge/')\n",
    "\n",
    "data_path = Path('/media/SSD/Abstraction and Reasoning/')\n",
    "training_path = data_path / 'training'\n",
    "test_path = data_path / 'test'\n",
    "program_path = data_path/'programs'\n",
    "\n",
    "training_tasks = sorted(os.listdir(training_path))\n",
    "testing_tasks = sorted(os.listdir(test_path))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting\n",
    "\n",
    "!!plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# This code is used to display a task\n",
    "# It accepts 11 colors, one more than the images, in case we want to use it\n",
    "# \n",
    "\n",
    "cmap = colors.ListedColormap(\n",
    "        ['#000000', '#0074D9','#FF4136','#2ECC40','#FFDC00',\n",
    "         '#AAAAAA', '#F012BE', '#FF851B', '#7FDBFF', '#870C25','#4a4d4a'])\n",
    "norm = colors.Normalize(vmin=0, vmax=10)\n",
    "def plot_one(ax,task, i,train_or_test,input_or_output):\n",
    "    cmap = colors.ListedColormap(\n",
    "        ['#000000', '#0074D9','#FF4136','#2ECC40','#FFDC00',\n",
    "         '#AAAAAA', '#F012BE', '#FF851B', '#7FDBFF', '#870C25','#4a4d4a'])\n",
    "    norm = colors.Normalize(vmin=0, vmax=10)\n",
    "    \n",
    "    try:\n",
    "        input_matrix = task[train_or_test][i][input_or_output]\n",
    "    except KeyError:\n",
    "        print(\"No\",train_or_test,input_or_output)\n",
    "    \n",
    "    else:\n",
    "    \n",
    "        ax.imshow(input_matrix, cmap=cmap, norm=norm)\n",
    "        ax.grid(True,which='both',color='lightgrey', linewidth=0.5)    \n",
    "        ax.set_yticks([x-0.5 for x in range(1+len(input_matrix))])\n",
    "        ax.set_xticks([x-0.5 for x in range(1+len(input_matrix[0]))])     \n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "        ax.set_title(train_or_test + ' '+input_or_output)\n",
    "    \n",
    "\n",
    "def plot_task(task):\n",
    "    \"\"\"\n",
    "    Plots the first train and test pairs of a specified task,\n",
    "    using same color scheme as the ARC app\n",
    "    \"\"\"    \n",
    "    num_train = len(task['train'])\n",
    "    fig, axs = plt.subplots(2, num_train, figsize=(3*num_train,3*2))\n",
    "    for i in range(num_train):     \n",
    "        plot_one(axs[0,i],task,i,'train','input')\n",
    "        plot_one(axs[1,i],task,i,'train','output')        \n",
    "    plt.tight_layout()\n",
    "    plt.show()        \n",
    "        \n",
    "    num_test = len(task['test'])\n",
    "    fig, axs = plt.subplots(2, num_test, figsize=(3*num_test,3*2))\n",
    "    if num_test==1: \n",
    "        plot_one(axs[0],task,0,'test','input')\n",
    "        plot_one(axs[1],task,0,'test','output')     \n",
    "    else:\n",
    "        for i in range(num_test):      \n",
    "            plot_one(axs[0,i],task,i,'test','input')\n",
    "            plot_one(axs[1,i],task,i,'test','output')  \n",
    "    plt.tight_layout()\n",
    "    plt.show() \n",
    "\n",
    "    \n",
    "# Display each output of the function\n",
    "def show_image_list(images):\n",
    "    \"\"\" Show each image contained in a list. \"\"\"\n",
    "    p = plt.figure(figsize=[17,5]).subplots(1, len(images))\n",
    "    \n",
    "    if len(images) > 1:\n",
    "        for i, image in enumerate(images):\n",
    "            p[i].imshow(image, cmap=cmap, norm=norm)\n",
    "    elif len(images) == 1:\n",
    "        p.imshow(images[0], cmap=cmap, norm=norm)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task Analysis Functions\n",
    "Used to characterize facts about a task\n",
    "\n",
    "\n",
    "!!analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def analyze_size(task, ignore_test_after = True):\n",
    "    \n",
    "    #print(\"\\n\\nSize\")\n",
    "    \n",
    "    \n",
    "    # scan befores training and test\n",
    "    di=np.zeros((0,2),int)\n",
    "    for i, t in enumerate(task[\"train\"]):\n",
    "        t_in = np.array(t[\"input\"])\n",
    "        di = np.vstack([di, t_in.shape])\n",
    "    \n",
    "    for i, t in enumerate(task[\"test\"]):\n",
    "        t_in = np.array(t[\"input\"])\n",
    "        di = np.vstack([di, t_in.shape])\n",
    "    #print(di) \n",
    "    \n",
    "    # scan afters training and test\n",
    "    do=np.zeros((0,2),int)\n",
    "    for i, t in enumerate(task[\"train\"]):\n",
    "        t_in = np.array(t[\"output\"])\n",
    "        do = np.vstack([do, t_in.shape])\n",
    "    \n",
    "    if not ignore_test_after:\n",
    "        for i, t in enumerate(task[\"test\"]):\n",
    "            t_in = np.array(t[\"input\"])\n",
    "            do = np.vstack([do, t_in.shape])\n",
    "    #print(do)        \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    d=np.zeros((len(task[\"train\"]),4),int)\n",
    "    \n",
    "    \n",
    "    for i, t in enumerate(task[\"train\"]):\n",
    "        t_in, t_out = np.array(t[\"input\"]), np.array(t[\"output\"])\n",
    "        d[i] = [t_in.shape[0], t_in.shape[1], t_out.shape[0], t_out.shape[1]]\n",
    "    \n",
    "    \n",
    "    \n",
    "    d2=np.zeros((len(task[\"test\"]),2),int)\n",
    "    for i, t in enumerate(task[\"test\"]):\n",
    "        t_in = np.array(t[\"input\"])\n",
    "        d2[i] = [t_in.shape[0], t_in.shape[1]]\n",
    "\n",
    "\n",
    "    #before_vert_test_train = np.unique(np.concatenate((d[:,0],d2[:,0])))\n",
    "    #before_hor_test_train = np.unique(np.concatenate((d[:,1],d2[:,1])))\n",
    "    \n",
    "    before_vert_test_train = np.unique(di[:,0])\n",
    "    before_hor_test_train = np.unique(di[:,1])\n",
    "   \n",
    "            \n",
    "            \n",
    "    #before_vert = np.unique(d[:,0])\n",
    "    #before_hor = np.unique(d[:,1])\n",
    "    #after_vert = np.unique(d[:,2])\n",
    "    #after_hor = np.unique(d[:,3])\n",
    "    \n",
    "    before_vert = np.unique(di[:,0])\n",
    "    before_hor = np.unique(di[:,1])\n",
    "    after_vert = np.unique(do[:,0])\n",
    "    after_hor = np.unique(do[:,1])\n",
    "    \n",
    "    #print(\"Unique before vertical:\",before_vert_test_train)    \n",
    "    #print(\"Unique before horizontal:\",before_hor_test_train)\n",
    "    #print(\"Unique after vertical:\",after_vert)\n",
    "    #print(\"Unique after horizontal:\",after_hor)\n",
    "    \n",
    "    \n",
    "    \n",
    "    ## Before == const 1 and After == Const 2\n",
    "    test1_before_vert = len(before_vert_test_train)  == 1\n",
    "    test1_after_vert = len(after_vert) == 1\n",
    "    test1_vert = test1_before_vert and test1_after_vert\n",
    "    \n",
    "    test1_before_hor = len(before_hor_test_train)  == 1\n",
    "    test1_after_hor = len(after_hor) == 1\n",
    "    test1_hor = test1_before_hor  == 1 and test1_after_hor\n",
    "    \n",
    "    ## Before == After == const\n",
    "    test2_vert = test1_vert and before_vert_test_train[0] == after_vert[0]\n",
    "    test2_hor = test1_hor and before_hor_test_train[0] == after_hor[0]\n",
    "    \n",
    "    ## Before(i) == After(i) all i\n",
    "    #test3_vert = np.all(d[:,0] == d[:,2])\n",
    "    #test3_hor = np.all(d[:,1] == d[:,3])\n",
    "    test3_vert = np.all(di[0:do.shape[0],0] == do[:,0])  # ignore any outputs without inputs\n",
    "    test3_hor = np.all(di[0:do.shape[0],1] == do[:,1])\n",
    "    \n",
    "    ##Test all Before are square\n",
    "    #test4 = np.all(np.concatenate((d[:,0],d2[:,0])) == np.concatenate((d[:,1],d2[:,1])))\n",
    "    test4 = np.all(di[:,0] == di[:,1])\n",
    "    \n",
    "    ## Test all After are square\n",
    "    #test5 = np.all(d[:,2] == d[:,3])\n",
    "    test5 = np.all(do[:,0] == do[:,1])\n",
    "\n",
    "    if test1_before_vert:\n",
    "        #print(\"Vertical: All Before ==\",before_vert[0])\n",
    "        test1_before_vert = before_vert[0]\n",
    "\n",
    "    if test1_before_hor:\n",
    "        #print(\"Horizontal: All Before ==\",before_hor[0])\n",
    "        test1_before_hor = before_hor[0]\n",
    "        \n",
    "    if test1_after_vert:\n",
    "        #print(\"Vertical: All After ==\",after_vert[0])\n",
    "        test1_after_vert = after_vert[0]\n",
    "\n",
    "    if test1_after_hor:\n",
    "        #print(\"Horizontal: All After ==\",after_hor[0])\n",
    "        test1_after_hor = after_hor[0]       \n",
    "                    \n",
    "    \n",
    "    if test2_vert:\n",
    "        #print(\"Vertical: All Before == After  == const : \", before_vert[0])\n",
    "        test2_vert = before_vert[0]\n",
    "    \n",
    "    if test2_hor:\n",
    "        #print(\"Horizontal: All Before == After  == const : \", before_hor[0])\n",
    "        test2_hor = before_hor[0]\n",
    "        \n",
    "    #if test3_vert:\n",
    "        #print(\"Vertical: For all i Before(i) == After(i) == const:\",d[:,0])\n",
    "        \n",
    "    \n",
    "    #if test3_hor:\n",
    "        #print(\"Horizontal: For all i Before(i) == After(i) == const:\",d[:,1])\n",
    "\n",
    "        \n",
    "    #if test4:\n",
    "        #print(\"All Befores are square.\")\n",
    "    #if test5:\n",
    "        #print(\"All Afters are square\")\n",
    "      \n",
    "    dt = {}\n",
    "    dt[\"Befores are Square\"] = test4\n",
    "    dt[\"Afters are Square\"] = test5\n",
    "    dt[\"All Befores have same Vertical\"] = test1_before_vert\n",
    "    dt[\"All Befores have same Horizontal\"] = test1_before_hor\n",
    "    dt[\"All Afters have same Vertical\"] = test1_after_vert\n",
    "    dt[\"All Afters have same Horizontal\"] = test1_after_hor\n",
    "    dt[\"All Befores and Afters have same Vertical\"] = test2_vert\n",
    "    dt[\"All Befores and Afters have same Horizontal\"] = test2_hor\n",
    "    dt[\"Every Before and After has same Vertical\"] = test3_vert\n",
    "    dt[\"Every Before and After has same Horizontal\"] = test3_hor\n",
    "    \n",
    "    \n",
    "    return dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_color(task, ignore_test_after = True):\n",
    "    #print(\"\\n\\nColor\")\n",
    "    b=[]\n",
    "    a=[]\n",
    "    dt={}\n",
    "    \n",
    "    after_m_before={}\n",
    "    before_m_after={}\n",
    "    before_after_union={}\n",
    "    before_after_intersection={}\n",
    "    before_after_symdiff={}\n",
    "    \n",
    "    before_sets=[]\n",
    "    after_sets=[]\n",
    "    \n",
    "    unions_after_m_before=set()\n",
    "    \n",
    "    for i, t in enumerate(task[\"train\"]):\n",
    "        \n",
    "        before_set = set(list_flatten(t[\"input\"]))\n",
    "        after_set = set(list_flatten(t[\"output\"]))\n",
    "        \n",
    "\n",
    "        \n",
    "        before_sets.append(before_set)\n",
    "        after_sets.append(after_set)\n",
    "        \n",
    "        \n",
    "        after_m_before[i] = after_set-before_set\n",
    "        before_m_after[i] = before_set-after_set\n",
    "        before_after_union[i] = before_set | after_set\n",
    "        before_after_intersection[i]=before_set & after_set\n",
    "        before_after_symdiff[i] = before_set ^ after_set\n",
    "        \n",
    "        # collect some sets across the examples\n",
    "        \n",
    "        if i == 0:\n",
    "            before_intersections = before_set\n",
    "            after_intersections = after_set\n",
    "            before_m_after_intersections = before_m_after[i]\n",
    "        else:\n",
    "            before_intersections = before_intersections & before_set\n",
    "            after_intersections = after_intersections & after_set\n",
    "            before_m_after_intersections = before_m_after_intersections & before_m_after[i]        \n",
    "        \n",
    "        unions_after_m_before = unions_after_m_before | after_m_before[i]\n",
    "        \n",
    "        \n",
    "        \n",
    "        #print(\"\\nbefore set=\",before_set)\n",
    "        #print(\"after set=\",after_set)\n",
    "        #print(\"Union=\",before_after_union[i])\n",
    "        #print(\"Intersection=\",before_after_intersection[i])\n",
    "        #print(\"before-after set=\",before_m_after[i])\n",
    "        #print(\"after-before set=\", after_m_before[i])\n",
    "        #print(\"Symm Diff=\",before_after_symdiff[i])\n",
    "        \n",
    "        # Get some counts\n",
    "        \n",
    "        t_in, t_out = np.array(t[\"input\"]), np.array(t[\"output\"])\n",
    "        before_unique, before_counts = np.unique(t_in,return_counts=True)\n",
    "        after_unique, after_counts = np.unique(t_out,return_counts=True)\n",
    "        #print(\"i=\",i,\" before=\",before_unique,\" after=\", after_unique)\n",
    "        b.append(before_unique)\n",
    "        a.append(after_unique)\n",
    "        \n",
    "\n",
    "        \n",
    "    bt=[]    \n",
    "    for i, t in enumerate(task[\"test\"]):\n",
    "        \n",
    "        before_set = set(list_flatten(t[\"input\"]))\n",
    "        before_sets.append(before_set)\n",
    "        \n",
    "        before_intersections = before_intersections & before_set\n",
    "        \n",
    "        t_in = np.array(t[\"input\"])\n",
    "        before_unique, before_counts = np.unique(t_in,return_counts=True)\n",
    "        bt.append(before_unique)\n",
    "        #print(\"i=\",i,\" before=\",before_unique)\n",
    "        \n",
    "        # Get some counts\n",
    "        t_in = np.array(t[\"input\"])\n",
    "        before_unique, before_counts = np.unique(t_in,return_counts=True)\n",
    "        b.append(before_unique)\n",
    "        \n",
    "        if not ignore_test_after and len(t)>1:  # check if there is an after test example\n",
    "            \n",
    "            after_set = set(list_flatten(t[\"output\"]))\n",
    "            after_sets.append(after_set)\n",
    " \n",
    "            after_m_before[i] = after_set-before_set\n",
    "            before_m_after[i] = before_set-after_set\n",
    "            before_after_union[i] = before_set | after_set\n",
    "            before_after_intersection[i]=before_set & after_set\n",
    "            before_after_symdiff[i] = before_set ^ after_set\n",
    "\n",
    "            # collect some sets across the examples\n",
    "            before_intersections = before_intersections & before_set\n",
    "            after_intersections = after_intersections & after_set\n",
    "            before_m_after_intersections = before_m_after_intersections & before_m_after[i]        \n",
    "        \n",
    "            unions_after_m_before = unions_after_m_before | after_m_before[i]\n",
    "\n",
    "            # Get some counts\n",
    "        \n",
    "            t_out = np.array(t[\"output\"])\n",
    "            print(\"t_out=\",t_out)\n",
    "            after_unique, after_counts = np.unique(t_out,return_counts=True)\n",
    "            a.append(after_unique)\n",
    "        \n",
    "        #unique colors that match\n",
    "        \n",
    "        #colors of unchanged pixels before and after\n",
    "        \n",
    "        \n",
    "        #Colors not in common in the befores\n",
    "        not_common_in_befores = set()\n",
    "        for i,s in enumerate(before_sets):\n",
    "            not_common_in_befores = not_common_in_befores | (s - before_intersections)\n",
    "        \n",
    "        #Colors not in common in the afters\n",
    "        not_common_in_afters = set()\n",
    "        for i,s in enumerate(after_sets):\n",
    "            not_common_in_afters = not_common_in_afters | (s - after_intersections)\n",
    "            \n",
    "    #print(\"Common colors=\"),before_intersections & after_intersections)\n",
    "    #print(\"Common colors in all Befores=\",before_intersections)\n",
    "    #print(\"Common colors in all Afters=\",after_intersections)\n",
    "    #print(\"Common colors taken from all Befores (Intersection of all Before-After)=\",before_m_after_intersections)\n",
    "    #print(\"All Colors Added to Afters (Union of all After-Before)=\",unions_after_m_before)\n",
    "    #print(\"Colors not common in Befores=\",not_common_in_befores)\n",
    "    #print(\"Colors not common in Afters=\",not_common_in_afters)\n",
    "    \n",
    "    dt={}\n",
    "    dt[\"Common colors\"] = before_intersections & after_intersections\n",
    "    dt[\"Common colors in all Befores\"] = before_intersections\n",
    "    dt[\"Common colors in all Afters\"] = after_intersections\n",
    "    dt[\"Common colors taken from all Befores\"] = before_m_after_intersections\n",
    "    dt[\"Colors not common in Befores\"] = not_common_in_befores\n",
    "    dt[\"Colors not common in Afters\"] = not_common_in_afters\n",
    "    \n",
    "    return dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis={}\n",
    "\n",
    "def analyze(task,ignore_test_after = True):\n",
    "    \n",
    "    global analysis\n",
    "    \n",
    "    analysis={}\n",
    "\n",
    "    analysis.update(analyze_size(task, ignore_test_after = True))\n",
    "    \n",
    "    analysis.update(analyze_color(task, ignore_test_after = True))\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_analysis():\n",
    "    global analysis\n",
    "    return(analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_dict(dt):\n",
    "    for x in dt:\n",
    "\n",
    "        print (x,':',dt[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/SSD/Abstraction and Reasoning/training/00d62c1b.json\n",
      "Befores are Square : True\n",
      "Afters are Square : True\n",
      "All Befores have same Vertical : False\n",
      "All Befores have same Horizontal : False\n",
      "All Afters have same Vertical : False\n",
      "All Afters have same Horizontal : False\n",
      "All Befores and Afters have same Vertical : False\n",
      "All Befores and Afters have same Horizontal : False\n",
      "Every Before and After has same Vertical : True\n",
      "Every Before and After has same Horizontal : True\n",
      "Common colors : {0, 3}\n",
      "Common colors in all Befores : {0, 3}\n",
      "Common colors in all Afters : {0, 3, 4}\n",
      "Common colors taken from all Befores : set()\n",
      "Colors not common in Befores : set()\n",
      "Colors not common in Afters : set()\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x432 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load my favorite task\n",
    "#task_file = str(training_path / training_tasks[1])\n",
    "#task_file = str(test_path / testing_tasks[1])\n",
    "\n",
    "def load_task(task_file):\n",
    "    \n",
    "    print(task_file)\n",
    "    with open(task_file, 'r') as f:\n",
    "        task = json.load(f)\n",
    "    analyze(task, ignore_test_after=True)\n",
    "\n",
    "    print_dict(get_analysis())\n",
    "\n",
    "    #show_image_list([[[0,1,2,3,4,5,6,7,8,9,10]]])\n",
    "    plot_task(task)\n",
    "    \n",
    "    return task\n",
    "        \n",
    "#task = load_task(task_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Domain Specific Language (DSL)**\n",
    "\n",
    "Our DSL will be a collection of functions of type `np.array -> [np.array]` and `[np.array] -> [np.array]`.\n",
    "\n",
    "The first kind of function take an image, and produce a list of images (for example, the image split by different colors). The second type of function take a list of images and produce a new list (for exemple, intersect).\n",
    "[](http://)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DSL Implementation\n",
    "\n",
    "We start with the functions that take *one image* and produce an *a list of images*.](http://)\n",
    "\n",
    "!!functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "# np.array -> [np.array]\n",
    "def groupByColorx_unlifted(pixmap):\n",
    "    \"\"\" Split an image into a collection of images with unique color \"\"\"    \n",
    "    # Count the number of colors\n",
    "    nb_colors = int(pixmap.max()) + 1\n",
    "    # Create a pixmap for each color\n",
    "    splited = [(pixmap == i) * i for i in range(1, nb_colors)]\n",
    "    # Filter out empty images - might not be needed since done in evaluate\n",
    "    return [x for x in splited if np.any(x)]\n",
    "\n",
    "def groupByColor_unlifted(pixmap):\n",
    "    \"\"\" Split an image into a collection of images with unique color \"\"\"\n",
    "    #Additions\n",
    "    #order the output based on common colors in after esp if in before too\n",
    "    \n",
    "    # Identify the colors\n",
    "    rng = np.unique(pixmap)\n",
    "    \n",
    "    # Create a pixmap for each color\n",
    "    splited = [ (pixmap == i) * i for i in rng]\n",
    "    #splited.append(pixmap)\n",
    "    return splited\n",
    "\n",
    "def agroupByColor_unlifted(pixmap):\n",
    "    \"\"\" Split an image into a collection of images with unique color \"\"\"\n",
    "    #Additions\n",
    "    #order the output based on common colors in befores\n",
    "    global analysis\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Identify the colors\n",
    "    rng = list(analysis['Common colors in all Befores'])\n",
    "    \n",
    "    # Create a pixmap for each color\n",
    "    splited = [ (pixmap == i) * i for i in rng]\n",
    "    #splited.append(pixmap)\n",
    "    return splited\n",
    "\n",
    "\n",
    "# np.array -> [np.array]\n",
    "def cropToContent_unlifted(pixmap):\n",
    "    \"\"\" Crop an image to fit exactly the non 0 pixels \"\"\"\n",
    "    \n",
    "    #Additions\n",
    "    #Crop to common colors\n",
    "    #Crop to common After size\n",
    "    \n",
    "    # Op argwhere will give us the coordinates of every non-zero point\n",
    "    true_points = np.argwhere(pixmap)\n",
    "    if len(true_points) == 0:\n",
    "        return []\n",
    "    # Take the smallest points and use them as the top left of our crop\n",
    "    top_left = true_points.min(axis=0)\n",
    "    # Take the largest points and use them as the bottom right of our crop\n",
    "    bottom_right = true_points.max(axis=0)\n",
    "    # Crop inside the defined rectangle\n",
    "    res = pixmap[top_left[0]:bottom_right[0]+1, top_left[1]:bottom_right[1]+1]\n",
    "    return [res]\n",
    "\n",
    "# np.array -> [np.array]\n",
    "def splitH_unlifted2(pixmap):\n",
    "    \"\"\" Split horizontally an image \"\"\"\n",
    "    h = pixmap.shape[0]\n",
    "    if h % 2 == 1:\n",
    "        h = h // 2\n",
    "        return [pixmap[:h,:], pixmap[h+1:,:]]\n",
    "    else:\n",
    "        h = h // 2\n",
    "        return [pixmap[:h,:], pixmap[h:,:]]\n",
    "    \n",
    "    \n",
    "def splitHn_unlifted(pixmap):\n",
    "    \"\"\" Split horizontally an image \"\"\"\n",
    "    \n",
    "    #Additions\n",
    "    #Split using common colors in before (not black first)\n",
    "    #Split based on common after horizontal size change\n",
    "    \n",
    "    ## find the split point based on the vertical line in the image\n",
    "    #look for vertical lines (unchnging color)\n",
    "    d=np.diff(pixmap, axis=0)\n",
    "    da=np.sum(np.abs(d), axis=0)  #columns with 0 are split options\n",
    "    loc=np.where(da == 0)[0]\n",
    "    im=[pixmap]\n",
    "    for p in loc:\n",
    "        #print(p)\n",
    "        im.append(pixmap[:,:p]) # left half no line\n",
    "        im.append(pixmap[:,p+1:])  # right half with no line\n",
    "\n",
    "    return(im)\n",
    "\n",
    "def splitH_unlifted(pixmap):\n",
    "    \"\"\" Split horizontally an image \"\"\"\n",
    "    \n",
    "    #Additions\n",
    "    #Split using common colors in before (not black first)\n",
    "    #Split based on common after horizontal size change\n",
    "    \n",
    "    ## find the split point based on the vertical line in the image\n",
    "    #look for vertical lines (unchnging color)\n",
    "    d=np.diff(pixmap, axis=0)\n",
    "    da=np.sum(np.abs(d), axis=0)  #columns with 0 are split options\n",
    "    loc=np.where(da == 0)[0]\n",
    "    im=[pixmap]\n",
    "    for p in loc:\n",
    "        #print(p)\n",
    "        im.append(pixmap[:,p:]) # right half with line\n",
    "        im.append(pixmap[:,:p+1]) # left half with line\n",
    "    return(im)\n",
    "\n",
    "\n",
    "def splitV_unlifted(pixmap):\n",
    "    \"\"\" Split horizontally an image \"\"\"\n",
    "    \n",
    "    #Additions\n",
    "    #Split using common colors in before (not black first)\n",
    "    #Split based on common after vertical size change\n",
    "    # Split on diagonal\n",
    "    \n",
    "    ## find the split point based on the horizontal line in the image\n",
    "    #look for horizontal lines (unchnging color)\n",
    "    d=np.diff(pixmap, axis=1)\n",
    "    da=np.sum(np.abs(d), axis=1)  #rows with 0 are split options\n",
    "    loc=np.where(da == 0)[0]\n",
    "    im=[pixmap]\n",
    "    for p in loc:\n",
    "        #print(p)\n",
    "        im.append(pixmap[p:,:]) # bot half with line\n",
    "        im.append(pixmap[:p+1,:]) # top half with line\n",
    "    return(im)\n",
    "\n",
    "def splitVn_unlifted(pixmap):\n",
    "    \"\"\" Split horizontally an image \"\"\"\n",
    "    \n",
    "    #Additions\n",
    "    #Split using common colors in before (not black first)\n",
    "    #Split based on common after vertical size change\n",
    "    # Split on diagonal\n",
    "     \n",
    "    ## find the split point based on the horizontal line in the image\n",
    "    #look for horizontal lines (unchnging color)\n",
    "    d=np.diff(pixmap, axis=1)\n",
    "    da=np.sum(np.abs(d), axis=1)  #rows with 0 are split options\n",
    "    loc=np.where(da == 0)[0]\n",
    "    im=[pixmap]\n",
    "    for p in loc:\n",
    "        #print(p)\n",
    "        im.append(pixmap[:p,:]) # top half no line\n",
    "        im.append(pixmap[p+1:,:])  # bot half with no line\n",
    "    return(im)\n",
    "\n",
    "\n",
    "\n",
    "def splitRD_unlifted(pixmap):\n",
    "    \"\"\" Split diagonally an image \"\"\"\n",
    "    \n",
    "    #Additions\n",
    "    #Split using common colors in before (not black first)\n",
    "    #Split based on common after vertical size change\n",
    "    # Split on diagonal\n",
    "    \n",
    "    ## find the split point based on the horizontal line in the image\n",
    "    #look for horizontal lines (unchnging color)\n",
    "\n",
    "    (v,h) = pixmap.shape\n",
    "    im=[pixmap]\n",
    "    if(v+h>4):\n",
    "        di = np.zeros((v+h-3, min(v,h)+1))\n",
    "\n",
    "        #create diagonal and find difference to search for solid diag\n",
    "        for t in range(2-v,h-1):\n",
    "            m = np.diag(pixmap,k=t)\n",
    "            p = 1+min(v,h)-len(m)\n",
    "            mp = np.pad(m,(1,p),mode = 'edge')\n",
    "            mpd =np.diff(mp) \n",
    "            #print(\"t=\",t,\"mp=\",mp)\n",
    "            i=t-(2-v)\n",
    "\n",
    "            di[i] = mpd\n",
    "\n",
    "        #print(\"di=\",di)\n",
    "        da=np.sum(np.abs(di), axis=1)  #rows with 0 are split options\n",
    "        loc=np.where(da == 0)[0]-v+2   \n",
    "        #print(\"loc=\",loc)\n",
    "\n",
    "        \n",
    "        for p in loc:\n",
    "            #print(p)\n",
    "            im.append(np.triu(pixmap,k=p)) # top part with line\n",
    "            im.append(np.tril(pixmap,k=p)) # bottom part with line\n",
    "    return(im)\n",
    "\n",
    "def splitLD_unlifted(pixmap):\n",
    "    res = splitRD_unlifted(np.rot90(pixmap, k=1))\n",
    "    \n",
    "    im=[np.rot90(m,k=-1 ) for m in res]\n",
    "    return(im)\n",
    "    \n",
    "\n",
    "# np.array -> [np.array]\n",
    "def negative_unlifted(pixmap):\n",
    "    \"\"\" Compute the negative of an image (and conserve the color) \"\"\"\n",
    "    #Additions\n",
    "    #choose color based on color changes between before and after\n",
    "    \n",
    "    negative = np.logical_not(pixmap).astype(int)\n",
    "    color = max(pixmap.max(), 1)  ##I think this picks largest color?\n",
    "    return [pixmap, negative * color]\n",
    "\n",
    "def extend_unlifted(pixmap):\n",
    "    \"\"\" Create image where original is padded by 30 pixels all around \"\"\"\n",
    "    \n",
    "    #Additions\n",
    "    #Pad to common size of After image, or rule (factor or addition)\n",
    "    \n",
    "    ##Check if already padded enough?  min dim >=90\n",
    "    if min(pixmap.shape) < 90 :\n",
    "        padded=np.pad(pixmap, ((30,30), (30, 30)), 'constant', constant_values=(0))\n",
    "        #return [padded, pixmap]\n",
    "        return [padded]\n",
    "    else:\n",
    "        #return [pixmap, pixmap]\n",
    "        return [pixmap]\n",
    "    \n",
    "\n",
    "\n",
    "def rotate_unlifted(pixmap):   \n",
    "    \n",
    "    #Additions\n",
    "    #Use pattern matching to decide rotation amount\n",
    "    return [pixmap, np.rot90(pixmap)]# rotated image by 90 deg\n",
    "\n",
    "def mirror_unlifted(pixmap):\n",
    "    return [pixmap, np.fliplr(pixmap)]# mirror image flip H\n",
    "\n",
    "def tile2_unlifted(pixmap):\n",
    "    \n",
    "    #Additions\n",
    "    #Use Common sizes to identify tiling amount\n",
    "    \n",
    "    image =  np.tile(pixmap, (2,2))\n",
    "    s = image.shape\n",
    "    h = min(s[0],90)\n",
    "    v = min(s[1],90)\n",
    "    #print(\"h=\",h,\" v=\",v)\n",
    "    return [pixmap, image[:h,:v]]\n",
    "\n",
    "def tile3_unlifted(pixmap):\n",
    "    \n",
    "    #Additions\n",
    "    #Use Common sizes to identify tiling amount\n",
    "    \n",
    "    image =  np.tile(pixmap, (3,3))\n",
    "    s = image.shape\n",
    "    h = min(s[0],90)\n",
    "    v = min(s[1],90)\n",
    "    #print(\"h=\",h,\" v=\",v)\n",
    "    return [pixmap, image[:h,:v]]\n",
    "\n",
    "def atile_unlifted(pixmap):\n",
    "    \n",
    "    #Additions\n",
    "    #Use Common sizes to identify tiling amount\n",
    "    global analysis\n",
    "        \n",
    "    h=3\n",
    "    v=3\n",
    "    \n",
    "    if analysis['All Befores have same Vertical'] and analysis['All Afters have same Vertical']:\n",
    "        v=int(analysis['All Afters have same Vertical']/analysis['All Befores have same Vertical'])\n",
    "        v=max(v,1)\n",
    "\n",
    "    if analysis['All Befores have same Horizontal'] and analysis['All Afters have same Horizontal']:\n",
    "        h=int(analysis['All Afters have same Horizontal']/analysis['All Befores have same Horizontal'])\n",
    "        h=max(h,1)\n",
    "    \n",
    "    \n",
    "    image =  np.tile(pixmap, (h,v))\n",
    "    s = image.shape\n",
    "    h = min(s[0],90)\n",
    "    v = min(s[1],90)\n",
    "    #print(\"h=\",h,\" v=\",v)\n",
    "    return [pixmap, image[:h,:v]]\n",
    "\n",
    "\n",
    "def tile3h_unlifted(pixmap):\n",
    "    \n",
    "    #Additions\n",
    "    #Use Common sizes to identify tiling amount\n",
    "    \n",
    "    image =  np.tile(pixmap, 3)\n",
    "    s = image.shape\n",
    "    h = min(s[0],90)\n",
    "    v = min(s[1],90)\n",
    "    #print(\"h=\",h,\" v=\",v)\n",
    "    return [pixmap, image[:h,:v]]\n",
    "\n",
    "def tile2h_unlifted(pixmap):\n",
    "    \n",
    "    #Additions\n",
    "    #Use Common sizes to identify tiling amount\n",
    "    \n",
    "    image =  np.tile(pixmap, 2)\n",
    "    s = image.shape\n",
    "    h = min(s[0],90)\n",
    "    v = min(s[1],90)\n",
    "    #print(\"h=\",h,\" v=\",v)\n",
    "    return [pixmap, image[:h,:v]]\n",
    "\n",
    "def shift_unlifted(pixmap):\n",
    "    return # shift image over by 1 to the right\n",
    "\n",
    "def zoom3_unlifted(pixmap):\n",
    "    \n",
    "    #Additions\n",
    "    #Check if square before using this.  Check common sizes\n",
    "    \n",
    "    newshape = np.array(pixmap.shape) * 3\n",
    "    slices = [ slice(0,old, float(old)/new) for old,new in zip(pixmap.shape,newshape) ]\n",
    "    coordinates = np.mgrid[slices]\n",
    "    indices = coordinates.astype('i')   #choose the biggest smaller integer index\n",
    "    \n",
    "    return [pixmap, pixmap[tuple(indices)]] # enlarge image taking each 1 pixel and making it 3x3\n",
    "\n",
    "def azoom_unlifted(pixmap):\n",
    "    \n",
    "    #Additions\n",
    "    #Check if square before using this.  Check common sizes\n",
    "    global analysis\n",
    "        \n",
    "    h=3\n",
    "    v=3\n",
    "    \n",
    "    if analysis['All Afters have same Vertical'] and analysis['All Afters have same Horizontal']:\n",
    "        v=analysis['All Afters have same Vertical']\n",
    "        v=max(v,1)\n",
    "        h=analysis['All Afters have same Horizontal']\n",
    "        h=max(h,1)\n",
    "        \n",
    "        \n",
    "        newshape = np.array((v,h))\n",
    "        slices = [ slice(0,old, float(old)/new) for old,new in zip(pixmap.shape,newshape) ]\n",
    "        coordinates = np.mgrid[slices]\n",
    "        indices = coordinates.astype('i')   #choose the biggest smaller integer index\n",
    "\n",
    "        return [pixmap, pixmap[tuple(indices)]] # enlarge image taking each 1 pixel and making it larger\n",
    "    else:\n",
    "        return [pixmap]\n",
    "\n",
    "\n",
    "def zoom2_unlifted(pixmap):\n",
    "\n",
    "    \n",
    "    #Additions\n",
    "    #Check if square before using this.  Check common sizes\n",
    "    \n",
    "    newshape = np.array(pixmap.shape) * 2\n",
    "    slices = [ slice(0,old, float(old)/new) for old,new in zip(pixmap.shape,newshape) ]\n",
    "    coordinates = np.mgrid[slices]\n",
    "    indices = coordinates.astype('i')   #choose the biggest smaller integer index\n",
    "    \n",
    "    return [pixmap, pixmap[tuple(indices)]] # enlarge image taking each 1 pixel and making it 2x2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def lzoom_unlifted(pixmap):\n",
    "\n",
    "    return #take small image and turn 1 pixel  2 horizontal, 1 into 3 horizontal  (with mirror and flip this can expand to other cases)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Composition of functions\n",
    "\n",
    "It is important to make sure we can chain both functions. It is clear how we can compose two functions `f` and `g` of type `[np.array] -> [np.array]` ; We symply call `g(f([input_image]))`.\n",
    "\n",
    "\n",
    "For each function of the first type, we need to generated a *lifted version*. A function `np.array -> [np.array]` is can be turned into a function of type `[np.array] -> [np.array]` simply by applying the first function on each image and concatenating the results.\n",
    "\n",
    "---\n",
    "If you want to know more about the `lift` function, have a look to the concept of [*monades*](https://en.wikipedia.org/wiki/Monad_%28functional_programming%29). We are indeed using the *list monade*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lift(fct):\n",
    "    # Lift the function\n",
    "    def lifted_function(xs):\n",
    "        list_of_results = [fct(x) for x in xs]\n",
    "        return list(itertools.chain(*list_of_results))\n",
    "    # Give a nice name to the lifted function\n",
    "    import re\n",
    "    lifted_function.__name__ = re.sub('_unlifted$', '_lifted', fct.__name__)\n",
    "    return lifted_function\n",
    "\n",
    "cropToContent = lift(cropToContent_unlifted)\n",
    "groupByColor = lift(groupByColor_unlifted)\n",
    "splitH = lift(splitH_unlifted)\n",
    "splitHn = lift(splitHn_unlifted)\n",
    "splitV = lift(splitV_unlifted)\n",
    "splitVn = lift(splitVn_unlifted)\n",
    "negative = lift(negative_unlifted)\n",
    "extend = lift(extend_unlifted)\n",
    "rotate = lift(rotate_unlifted)\n",
    "mirror = lift(mirror_unlifted)\n",
    "tile2 = lift(tile2_unlifted)\n",
    "tile3 = lift(tile3_unlifted)\n",
    "tile2h = lift(tile2h_unlifted)\n",
    "tile3h = lift(tile3h_unlifted)\n",
    "zoom3 = lift(zoom3_unlifted)\n",
    "zoom2 = lift(zoom2_unlifted)\n",
    "\n",
    "agroupByColor = lift(agroupByColor_unlifted)\n",
    "atile = lift(atile_unlifted)\n",
    "azoom = lift(azoom_unlifted)\n",
    "splitRD = lift(splitRD_unlifted)\n",
    "splitLD = lift(splitLD_unlifted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!!functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [np.array] -> [np.array]\n",
    "def identity(x: [np.array]):\n",
    "    return x\n",
    "\n",
    "# [np.array] -> [np.array]\n",
    "def tail(x):\n",
    "    if len(x) > 1:\n",
    "        return x[1:]\n",
    "    else:\n",
    "        return x\n",
    "    \n",
    "def head(x):\n",
    "    if len(x) > 1:\n",
    "        return x[:-1]\n",
    "    else:\n",
    "        return x    \n",
    "    \n",
    "def swap(x):\n",
    "\n",
    "    if len(x) > 1:\n",
    "        t=x[-1]\n",
    "        x[-1]=x[-2]\n",
    "        x[-2]=t\n",
    "    \n",
    "    return x   \n",
    "\n",
    "\n",
    "def dedupe(x):\n",
    "    \"\"\" Dedupes a list of images using numpy - string - dict - string - numpy conversion \"\"\"   \n",
    "    l1=[str(pixmap.tolist()) for pixmap in x]\n",
    "    unique_str_list = list(dict.fromkeys(l1))\n",
    "    x = [np.array(ast.literal_eval(s)) for s in unique_str_list]\n",
    "    return x\n",
    "\n",
    "# [np.array] -> [np.array]\n",
    "def init(x):\n",
    "    if len(x) > 1:\n",
    "        return x[:1]\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "# [np.array] -> [np.array]\n",
    "def union2(x):\n",
    "    \"\"\" Compute the pixel union of all images in the list. \"\"\"\n",
    "    if len(x) < 2:\n",
    "        return x\n",
    "    \n",
    "    # Make sure everybody have the same shape\n",
    "    first_shape = tuple(x[0].shape)\n",
    "    for pixmap in x[1:]:\n",
    "        if first_shape != tuple(pixmap.shape):\n",
    "            return []\n",
    "    \n",
    "    return [np.bitwise_or.reduce(np.array(x).astype(int))]\n",
    "    \n",
    "def intersect2(x):\n",
    "    \"\"\" Compute the pixel intersection of all images in the list. \"\"\"\n",
    "    if len(x) < 2:\n",
    "        return x\n",
    "    \n",
    "    # Make sure everybody have the same shape\n",
    "    first_shape = tuple(x[0].shape)\n",
    "    for pixmap in x[1:]:\n",
    "        if first_shape != tuple(pixmap.shape):\n",
    "            return []\n",
    "    \n",
    "    return [(np.prod(np.array(x), axis=0) > 0).astype(int)]\n",
    "\n",
    "def union(x):\n",
    "    \n",
    "    if len(x) < 2:\n",
    "        return x\n",
    "    l={}\n",
    "    # search list to identify shapes and counts\n",
    "    for pixmap in x:\n",
    "        s=str(pixmap.shape)\n",
    "        try:\n",
    "            l[s].append(pixmap)\n",
    "        except KeyError:\n",
    "            l[s]=[pixmap]\n",
    "    \n",
    "    im=[]\n",
    "    for i, k in enumerate(l):\n",
    "    #print(i, k,len(l[k]))\n",
    "        if len(l[k])>1:\n",
    "            mask = (np.logical_or.reduce(np.array(l[k]))).astype(int)\n",
    "            #print(mask)\n",
    "            for j,m in enumerate(l[k]):\n",
    "                #print()\n",
    "                im.append(np.prod([mask, m], axis=0) )\n",
    "\n",
    "    return im\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "def intersect(x):\n",
    "    \n",
    "    if len(x) < 2:\n",
    "        return x\n",
    "    l={}\n",
    "    # search list to identify shapes and counts\n",
    "    for pixmap in x:\n",
    "        s=str(pixmap.shape)\n",
    "        try:\n",
    "            l[s].append(pixmap)\n",
    "        except KeyError:\n",
    "            l[s]=[pixmap]\n",
    "    \n",
    "    im=[]\n",
    "    for i, k in enumerate(l):\n",
    "    #print(i, k,len(l[k]))\n",
    "        if len(l[k])>1:\n",
    "            mask = (np.prod(np.array(l[k]), axis=0) > 0).astype(int)\n",
    "            for j,m in enumerate(l[k]):\n",
    "                #print()\n",
    "                im.append(np.prod([mask, m], axis=0) )\n",
    "\n",
    "    return im\n",
    "\n",
    "#def subtract(x):\n",
    "        \n",
    "    #Additions\n",
    "    #Use set difference to produce a new image from a bunch of existing\n",
    "    \n",
    "    \n",
    "def sortByColor(xs):\n",
    "    \"\"\" Sort pictures by increasing color id. \"\"\"\n",
    "    \n",
    "    #Additions\n",
    "    #Use common colors to decide \n",
    "    \n",
    "    \n",
    "    \n",
    "    xs = [x for x in xs if len(x.reshape(-1)) > 0]\n",
    "    return list(sorted(xs, key=lambda x: x.max()))\n",
    "\n",
    "def asortByColor(xs):\n",
    "    \"\"\" Sort pictures by increasing color id. \"\"\"\n",
    "    \n",
    "    #Additions\n",
    "    #Use common colors to decide \n",
    "    global analysis\n",
    "        \n",
    "    c=analysis[\"Common colors in all Afters\"]\n",
    "    \n",
    "    #for x in xs:\n",
    "        #print(\"set=\",set(x.flatten().tolist()))\n",
    "        #print(\"len=\",len(set(x.flatten().tolist()) & c))\n",
    "    \n",
    "    # get number of intersecting colors with common\n",
    "       \n",
    "    xs = [x for x in xs if len(x.reshape(-1)) > 0]\n",
    "    return list(sorted(xs, key=lambda x: len(set(x.flatten().tolist()) & c)))\n",
    "\n",
    "def sortByWeight(xs):\n",
    "    \"\"\" Sort images by how many non zero pixels are contained. \"\"\"\n",
    "    xs = [x for x in xs if len(x.reshape(-1)) > 0]\n",
    "    return list(sorted(xs, key=lambda x: (x>0).sum()))\n",
    "\n",
    "def reverse(x):\n",
    "    \"\"\" Reverse the order of a list of images. \"\"\"\n",
    "    return x[::-1]\n",
    "\n",
    "def colorshift(x):\n",
    "    \n",
    "    \n",
    "    #Additions\n",
    "    #Use common colors to shift from before colors to after colors \n",
    "    \n",
    "    \n",
    "    \n",
    "    im=[]\n",
    "    for pixmap in x:\n",
    "        pixmap=pixmap+1\n",
    "        pixmap[pixmap==1] = 0 # turn black to black again\n",
    "        pixmap[pixmap>10] = 1 # rotate to 1\n",
    "        im.append(pixmap)\n",
    "    return im\n",
    "\n",
    "def stackv(x):  ## join images top to bottom\n",
    "    if len(x) < 2:\n",
    "        return x\n",
    "    l={}\n",
    "    # search list to identify shapes and counts\n",
    "    for pixmap in x:\n",
    "        s=pixmap.shape[1]\n",
    "        try:\n",
    "            l[s].append(pixmap)\n",
    "        except KeyError:\n",
    "            l[s]=[pixmap]\n",
    "    \n",
    "    im=[]\n",
    "    for i, k in enumerate(l):\n",
    "    #print(i, k,len(l[k]))\n",
    "        if len(l[k])>1: ## more than one image with this dimension\n",
    "            im.append(np.vstack(l[k]) )\n",
    "\n",
    "    return im\n",
    "\n",
    "def stackh(x):  ## join images top to bottom\n",
    "    if len(x) < 2:\n",
    "        return x\n",
    "    l={}\n",
    "    # search list to identify shapes and counts\n",
    "    for pixmap in x:\n",
    "        s=pixmap.shape[0]\n",
    "        try:\n",
    "            l[s].append(pixmap)\n",
    "        except KeyError:\n",
    "            l[s]=[pixmap]\n",
    "    \n",
    "    im=[]\n",
    "    for i, k in enumerate(l):\n",
    "    #print(i, k,len(l[k]))\n",
    "        if len(l[k])>1: ## more than one image with this dimension\n",
    "            im.append(np.hstack(l[k]) )\n",
    "\n",
    "    return im\n",
    "\n",
    "\n",
    "stack=[]\n",
    "\n",
    "def push(x):  ## push last image on a stack\n",
    "    if len(x) < 2:\n",
    "        return x    \n",
    "    stack.append(x[-1])\n",
    "    return x[:-1]\n",
    "\n",
    "def pull(x):\n",
    "    if(len(stack)>1):\n",
    "        x.append(stack.pop())\n",
    "    elif(len(stack)>0):\n",
    "        x.append(stack[-1])\n",
    "    return x\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Program evaluation\n",
    "\n",
    "\n",
    "We define our building blocks for programs (the functions in our DSL). We will define a program as a list of functions from our DSL ; `program: [[np.array] -> [np.array]]`. The instructions in our programs will be executed *from left to right*. This mean that if we want to first `splitByColor` and then compute the `negative` of the image, we need to write `[splitByColor, negative]` in this order."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first write an utilitary function to describe a program as a human readable string.\n",
    "\n",
    "!!evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[splitH, groupByColor, negative, intersect]\n"
     ]
    }
   ],
   "source": [
    "def program_desc(program):\n",
    "    \"\"\" Create a human readable description of a program. \"\"\"\n",
    "    desc = [x.__name__.replace(\"_lifted\", \"\") for x in program]\n",
    "    return('['+', '.join(desc)+']')\n",
    "\n",
    "# Display the program description alongside its output\n",
    "program = [splitH, groupByColor, negative, intersect]\n",
    "print(program_desc(program))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The evaluation method\n",
    "We need a way to run a such program on a pictures and recover the result. This is done by the `evaluate` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(program: [], input_image: np.array):\n",
    "    \n",
    "    image_list = [np.array(input_image)]\n",
    "    # Make sure the input is a np.array\n",
    "    #input_image = np.array(input_image, dtype=\"int8\")\n",
    "    #input_image = np.array(input_image)\n",
    "    #assert type(input_image) == np.ndarray\n",
    "    \n",
    "    # Apply each function on the image\n",
    "    #image_list = [input_image]\n",
    "    for fct in program:\n",
    "        # Apply the function\n",
    "        #image_list.append(input_image)  ##try this to get input in every step\n",
    "        image_list = fct(image_list)\n",
    "        # Filter out empty images\n",
    "        image_list = [img for img in image_list if img.shape[0] > 0 and img.shape[1] > 0]\n",
    "        # Break if there is no data\n",
    "        #if image_list == []:\n",
    "            #return []\n",
    "    return image_list[-20:]       ## limit image list to 20   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Program generation\n",
    "\n",
    "We now have a simple and powerful language to express various transformation on images. But someone or something still have to write the actual program that can solve a task. In this part, we will implement a naive but somewhat efficient genetic algorithm that will be able to find by itself the solution to a task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Is a program solution\n",
    "\n",
    "First, we need a way to know if a program is a solution of the given examples of a task.\n",
    "\n",
    "!!is solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'task' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-dfc126b6f2a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mprogram\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtile3h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmirror\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtile3h\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstackv\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprogram_desc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprogram\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"is a solution of the task:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_solution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprogram\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'task' is not defined"
     ]
    }
   ],
   "source": [
    "def are_two_images_equals(a, b):\n",
    "    if tuple(a.shape) == tuple(b.shape):\n",
    "        if (np.abs(b-a) < 1).all():\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def is_solution(program, task, verbose=True):\n",
    "    for sample in task: # For each pair input/output\n",
    "        \n",
    "        i = np.array(sample['input'])\n",
    "        o = np.array(sample['output'])\n",
    "\n",
    "        # Evaluate the program on the input\n",
    "        images = evaluate(program, i)\n",
    "        if len(images) < 1:\n",
    "            return False\n",
    "        \n",
    "        # The solution should be in the 3 last outputs\n",
    "        images = images[-3:]\n",
    "        #print(\"Images=\",images) #debug\n",
    "        # Check if the output is in the 3 images produced\n",
    "        is_program_of_for_sample = any([are_two_images_equals(x, o) for x in images])\n",
    "        if not is_program_of_for_sample:\n",
    "            return False\n",
    "    \n",
    "    return True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see https://stackoverflow.com/questions/7670112/finding-a-subimage-inside-a-numpy-image\n",
    "\n",
    " \n",
    "def subimg_location(haystack, needle):\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        haystack_str = b\"\".join(48+haystack.flatten().astype(np.dtype('b'))).decode(\"latin-1\") \n",
    "        needle_str = b\"\".join((48+needle.flatten()).astype(np.dtype('b'))).decode(\"latin-1\") \n",
    "    except:\n",
    "        print(\"needle=\",needle)\n",
    "        print(\"type=\",type(needle))\n",
    "        print(\"shape=\",needle.shape)\n",
    "        print(\"temp=\",temp)\n",
    "        print(\" \")\n",
    "    \n",
    "\n",
    "    gap_size = (haystack.shape[1] - needle.shape[1]) \n",
    "    \n",
    "    #print(gap_size)\n",
    "    gap_regex = '.{' + str(gap_size) + '}'\n",
    "\n",
    "    #print(gap_regex)\n",
    "    # Split b into needle.size[0] chunks\n",
    "    chunk_size = needle.shape[1] \n",
    "    split = [needle_str[i:i+chunk_size] for i in range(0, len(needle_str), chunk_size)]\n",
    "\n",
    "    # Build regex\n",
    "    regex = re.escape(split[0])\n",
    "    for i in range(1, len(split)):\n",
    "        regex += gap_regex + re.escape(split[i])\n",
    "\n",
    "    p = re.compile(regex)\n",
    "    m = p.search(haystack_str)\n",
    "\n",
    "    if not m:\n",
    "        return False\n",
    "\n",
    "    x, _ = m.span()\n",
    "\n",
    "    left = x % (haystack.shape[1] ) \n",
    "    top  = int(x / haystack.shape[1] )\n",
    "\n",
    "    return (top, left)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitness\n",
    "\n",
    "To help our algorithm progress in the right direction, we need a way to give a score to an existing program. The smaller is the score of the program, the closer we are to the solution. One can think of this score as a distance of our program to the optimal solution.\n",
    "\n",
    "Notice that one can think of this program as a minimization problem (minimize `score`) or maximization problem (minimize `-score`). On machine learning it is common to minimise a distance wereas in genetic algorithm literature you can read that we maximize the fitness of an agent. Both convention work perfectly, but it is more convenient if we choose one and stick to it. Therefore, we will MINIMIZE the score of our programs.\n",
    "\n",
    "First, we are going to evaluate how our program perform on different aspects.\n",
    "\n",
    "!!fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def width_fitness(predicted, expected_output):\n",
    "    \"\"\" How close the predicted image is to have the right width. Less is better.\"\"\"\n",
    "    return np.abs(predicted.shape[0] - expected_output.shape[0])\n",
    "\n",
    "def height_fitness(predicted, expected_output):\n",
    "    \"\"\" How close the predicted image is to have the right height. Less is better.\"\"\"\n",
    "    return np.abs(predicted.shape[1] - expected_output.shape[1])\n",
    "\n",
    "def activated_pixels_fitness(p, e):\n",
    "    \"\"\" How close the predicted image to have the right pixels. Less is better.\"\"\"\n",
    "    shape = (max(p.shape[0], e.shape[0]), max(p.shape[1], e.shape[1]))\n",
    "    diff = np.zeros(shape, dtype=int)\n",
    "    diff[0:p.shape[0], 0:p.shape[1]] = (p > 0).astype(int)\n",
    "    diff[0:e.shape[0], 0:e.shape[1]] -= (e > 0).astype(int)\n",
    "    \n",
    "    fit = (diff != 0).sum()\n",
    "    \n",
    "    return fit\n",
    "\n",
    "\n",
    "def submatch_fitness(p,e):\n",
    "    \n",
    "    (py,px) = p.shape\n",
    "    (ey,ex) = e.shape\n",
    "    \n",
    "    if px<=ex and py<=ey:\n",
    "        \n",
    "        r = subimg_location(haystack=e,needle=p)\n",
    "    \n",
    "    elif px>=ex and py>=ey:\n",
    "        r = subimg_location(haystack=p,needle=e)\n",
    "    elif px<ex and py>=ey:\n",
    "        \n",
    "        r = subimg_location(haystack=e[:,:px],needle=p)\n",
    "    elif px>=ex and py<ey:\n",
    " \n",
    "        r = subimg_location(haystack=e[:py,:],needle=p)\n",
    "    else:\n",
    "        print(\"whats up\",px,ex,py,ey)\n",
    "            \n",
    "    if r == False:\n",
    "        return 1\n",
    "    else:\n",
    "        #print(r)\n",
    "        return 0\n",
    "        \n",
    "\n",
    "def pixels_match_fitness(p,e):\n",
    "    shape = (max(p.shape[0], e.shape[0]), max(p.shape[1], e.shape[1]))\n",
    "    #check how many pixels match the expected output.\n",
    "    p1 = np.zeros(shape, dtype=int)\n",
    "    e1 = np.zeros(shape, dtype=int)\n",
    "    \n",
    "    p1[0:p.shape[0], 0:p.shape[1]] = p\n",
    "    e1[0:e.shape[0], 0:e.shape[1]] = e\n",
    "    \n",
    "    #q=np.abs(p1-e1).sum() + abs(e.shape[0]-p.shape[0])*abs(e.shape[1]-p.shape[1])\n",
    "    q=np.abs(p1-e1).sum()\n",
    "    \n",
    "    s=submatch_fitness(p,e)\n",
    "    \n",
    "    return q*(1+5*s)\n",
    "    \n",
    "\n",
    "def colors_fitness(p, e):\n",
    "    p_colors = np.unique(p)\n",
    "    e_colors = np.unique(e)\n",
    "    \n",
    "    nb_inter = len(np.intersect1d(p_colors, e_colors))\n",
    "\n",
    "    return (len(p_colors) - nb_inter) + (len(e_colors) - nb_inter)\n",
    "\n",
    "fitness_functions = [colors_fitness, activated_pixels_fitness, height_fitness, width_fitness, pixels_match_fitness]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fitness score (less is better) of our function will be a 4-dimensional tuple containing the result of each of the fitness functions.\n",
    "\n",
    "We want to be able to compare two score. Unfortunately, the *lixocographical order* is not adapted, as there is no reason than having a small `width score` is better than having a small `height score`. We are going to define a partial order that give the same weight to any fitness function.\n",
    "\n",
    "When we compare two tuple with this partial order, `(3, 2, 4, 0) < (3, 2, 5, 0)` and `(3, 2, 4, 0) < (4, 2, 4, 0)`. But there is no way to compare `(3, 2, 5, 0)` and `(4, 2, 4, 0)`. We say this two values are *incomparable*. If two score are incomparable, it means that we cannot say that one program is better than the over."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def product_less(a, b):\n",
    "    \"\"\" Return True iff the two tuples a and b respect a<b for the partial order. \"\"\"\n",
    "    a = np.array(a)\n",
    "    b = np.array(b)\n",
    "    return (np.array(a) < np.array(b)).all()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now write a function that evaluate the fitness of a program on a task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'task' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-658147b94b32>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Fitness evaluation:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_fitness\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtile3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'task' is not defined"
     ]
    }
   ],
   "source": [
    "# ([[np.array] -> [np.array]], Taks) -> (int, int, ..., int)\n",
    "def evaluate_fitness(program, task):\n",
    "    \"\"\" Take a program and a task, and return its fitness score as a tuple. \"\"\"\n",
    "    score = np.zeros((len(fitness_functions)+1))\n",
    "    \n",
    "    # For each sample\n",
    "    for sample in task:\n",
    "        i = np.array(sample['input'])\n",
    "        o = np.array(sample['output'])\n",
    "        images = evaluate(program, i)\n",
    "        \n",
    "        # For each fitness function\n",
    "        for index, fitness_function in enumerate(fitness_functions):\n",
    "            #images = evaluate(program, i)   ### This can be pulled out of loop\n",
    "            if images == []: # Penalize no prediction!\n",
    "                score[index] += 500\n",
    "            else: # Take only the score of the last 3 outputs\n",
    "                score[index]=0\n",
    "                im3=images[-3:]\n",
    "                for imct in range(len(im3)):\n",
    "                    score[index] = score[index] + fitness_function(im3[imct], o)/len(im3)\n",
    "        index=index+1\n",
    "        score[index]=len(images)  ## add a fitness function that penalizes # images\n",
    "                \n",
    "    return tuple(score)\n",
    "\n",
    "#print(\"Fitness evaluation:\", evaluate_fitness([tile3,], task['train']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Asexual reproduction\n",
    "\n",
    "Now that we can compare two programs we need a way to generate some of them. We will generate them randomly from a pool of best candidate.\n",
    "\n",
    "For the initial run, and also to be able to evaluate fresh candidates, we will also allow spontaneous generation of new born one instruction programs.\n",
    "\n",
    "!!reproduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def build_candidates(allowed_nodes=[identity], best_candidates=[], nb_candidates=100):\n",
    "    \"\"\"\n",
    "    Create a poll of fresh candidates using the `allowed_nodes`.\n",
    "    \n",
    "    The pool contain a mix of new single instructions programs\n",
    "    and mutations of the best candidates.\n",
    "    \"\"\"\n",
    "    \n",
    "    #Additions\n",
    "    #Choose candidates based on probabilities\n",
    "    #Choose candidates based on analysis of the task (give rotate higher prob if pattern matching shows rotated ims)\n",
    "    new_candidates = []\n",
    "    length_limit = 5 # Maximal length of a program\n",
    "    \n",
    "    def random_node():\n",
    "        return random.choice(allowed_nodes)\n",
    "    \n",
    "    # Until we have enougth new candidates\n",
    "    while(len(new_candidates) < nb_candidates):\n",
    "        # Add 10 new programs\n",
    "        for i in range(5):\n",
    "            new_candidates += [[random_node()]]\n",
    "        \n",
    "        # Create new programs based on each best candidate\n",
    "        for best_program in best_candidates:\n",
    "            # Add one op on its right but limit the length of the program\n",
    "            if len(best_program) < length_limit - 1:\n",
    "                new_candidates += [[random_node()] + best_program]\n",
    "            # Add one op on its left but limit the length of the program\n",
    "            if len(best_program) < length_limit - 1:\n",
    "                new_candidates += [best_program + [random_node()]]\n",
    "            # Mutate one instruction of the existing program\n",
    "            new_candidates += [list(best_program)]\n",
    "            new_candidates[-1][random.randrange(0, len(best_program))] = random_node()\n",
    "   \n",
    "    # Truncate if we have too many candidates\n",
    "    np.random.shuffle(new_candidates)\n",
    "    return new_candidates[:nb_candidates]\n",
    "\n",
    "# Test the function by building some candidates\n",
    "#len(build_candidates(allowed_nodes=[identity], best_candidates=[[identity]], nb_candidates=42))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find a program given a task\n",
    "\n",
    "This is the last step to our genetic algorithm. We have all the building blocks:\n",
    " * Generating both new programs and mutation of existing solutions\n",
    " * Evaluating the fitness score of a program\n",
    " * Comparing two programs to know if one perform better than the other\n",
    " * Detecting when a solution was found\n",
    " \n",
    "We can now write a function that will keep generating programs with increasing complexity until a solution is found.\n",
    "\n",
    "Using our partial order, we are going to keep the best candidates. Because the order is partial,\n",
    "there is no bound on how many uncomparables candidates we may have at a given iteration.\n",
    "\n",
    "!!build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_model(task, max_iterations=20, verbose=True):\n",
    "    \n",
    "    #Additions\n",
    "    #Convert a task to numpy arrays once instead of in each eval\n",
    "    \n",
    "    \n",
    "    \n",
    "    candidates_nodes = [\n",
    "        intersect,\n",
    "        \n",
    "        cropToContent, groupByColor, splitH, splitV,splitVn, splitHn,\n",
    "        tile2,tile3,zoom3,zoom2,union,sortByColor, mirror,rotate,colorshift,\n",
    "        tile2h,tile3h,stackh,stackv,head,\n",
    "        init,tail, sortByWeight, reverse, negative,swap,\n",
    "        \n",
    "        agroupByColor,atile,asortByColor\n",
    "        \n",
    "        #extend,push,pull,dedupe,azoom,splitRD,splitLD\n",
    "\n",
    "    ]\n",
    "    \n",
    "    #print(\"Task=\",task)\n",
    "    #print(\"max_iterations=\",max_iterations)\n",
    "    #print('verbose=',verbose)\n",
    "    print(\".\")\n",
    "    if verbose:\n",
    "        print(\"Candidates nodes are:\", [program_desc([n]) for n in candidates_nodes])\n",
    "        print()\n",
    "\n",
    "    best_candidates = {} # A dictionary of {score:candidate}\n",
    "    for i in range(max_iterations):\n",
    "        if verbose:\n",
    "            print(\"Iteration \", i+1)\n",
    "            print(\"-\" * 10)\n",
    "        \n",
    "        # Create a list of candidates\n",
    "        candidates = build_candidates(candidates_nodes, best_candidates.values())\n",
    "        \n",
    "        # Keep candidates with best fitness.\n",
    "        # They will be stored in the `best_candidates` dictionary\n",
    "        # where the key of each program is its fitness score.\n",
    "        for candidate in candidates:\n",
    "            score = evaluate_fitness(candidate, task)\n",
    "            is_uncomparable = True # True if we cannot compare the two candidate's scores\n",
    "            \n",
    "            # Compare the new candidate to the existing best candidates\n",
    "            best_candidates_items = list(best_candidates.items())\n",
    "            for best_score, best_candidate in best_candidates_items:\n",
    "                if product_less(score, best_score):\n",
    "                    # Remove previous best candidate and add the new one\n",
    "                    del best_candidates[best_score]\n",
    "                    best_candidates[score] = candidate\n",
    "                    is_uncomparable = False # The candidates are comparable\n",
    "                if product_less(best_score, score) or best_score == score:\n",
    "                    is_uncomparable = False # The candidates are comparable\n",
    "            if is_uncomparable: # The two candidates are uncomparable\n",
    "                best_candidates[score] = candidate\n",
    "\n",
    "        # For each best candidate, we look if we have an answer\n",
    "        for program in best_candidates.values():\n",
    "            if is_solution(program, task):\n",
    "                return program\n",
    "            \n",
    "        # Give some informations by selecting a random candidate\n",
    "        if verbose:\n",
    "            print(\"Best candidates length:\", len(best_candidates))\n",
    "            random_candidate_score = random.choice(list(best_candidates.keys()))\n",
    "            print(\"Random candidate score:\", random_candidate_score)\n",
    "            print(\"Random candidate implementation:\", program_desc(best_candidates[random_candidate_score]))\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solving the task\n",
    "\n",
    "We now apply our knowledge to solving the first task presented. We will run our algorithm and see how long it takes to generate a program that can solve the task. You may run the folowing cell multiple times to see the variance into how long the algorithm takes to find the answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing the data\n",
    "\n",
    "!!processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_build_model(taskfn, task_path = training_path, prog_path=program_path,max_iterations=20, verbose=True):\n",
    "    task_file = str(task_path / taskfn)\n",
    "    with open(task_file, 'r') as f:\n",
    "        task = json.load(f)\n",
    "     \n",
    "    #plot_task(task)\n",
    "    analyze(task,ignore_test_after = True)\n",
    "    program = build_model(task=task['train'],max_iterations=max_iterations, verbose=verbose)\n",
    "    if program is None:\n",
    "        print(\"No program was found for task: \", taskfn)\n",
    "    else:\n",
    "        print(\"Program was found for task: \", taskfn, \"= \",program_desc(program))\n",
    "        prog_file = program_path/(\"prog_\"+taskfn)\n",
    "        with open(prog_file, 'w') as f:\n",
    "            json.dump(program_desc(program), f)\n",
    "        \n",
    "    return program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      "No program was found for task:  00576224.json\n",
      ".\n",
      "No program was found for task:  009d5c81.json\n",
      ".\n",
      "No program was found for task:  00dbd492.json\n",
      ".\n",
      "No program was found for task:  03560426.json\n",
      ".\n",
      "No program was found for task:  05a7bcf2.json\n",
      ".\n",
      "No program was found for task:  0607ce86.json\n",
      ".\n",
      "No program was found for task:  0692e18c.json\n",
      ".\n",
      "No program was found for task:  070dd51e.json\n",
      ".\n",
      "No program was found for task:  08573cc6.json\n",
      ".\n",
      "No program was found for task:  0934a4d8.json\n",
      ".\n",
      "No program was found for task:  09c534e7.json\n",
      ".\n",
      "No program was found for task:  0a1d4ef5.json\n",
      ".\n",
      "No program was found for task:  0a2355a6.json\n",
      ".\n",
      "No program was found for task:  0b17323b.json\n",
      ".\n",
      "No program was found for task:  0bb8deee.json\n",
      ".\n",
      "No program was found for task:  0becf7df.json\n",
      ".\n",
      "No program was found for task:  0c786b71.json\n",
      ".\n",
      "No program was found for task:  0c9aba6e.json\n",
      ".\n",
      "No program was found for task:  0d87d2a6.json\n",
      ".\n",
      "No program was found for task:  0e671a1a.json\n",
      ".\n",
      "No program was found for task:  0f63c0b9.json\n",
      ".\n",
      "No program was found for task:  103eff5b.json\n",
      ".\n",
      "No program was found for task:  11e1fe23.json\n",
      ".\n",
      "No program was found for task:  12422b43.json\n",
      ".\n",
      "No program was found for task:  12997ef3.json\n",
      ".\n",
      "No program was found for task:  12eac192.json\n",
      ".\n",
      "No program was found for task:  136b0064.json\n",
      ".\n",
      "No program was found for task:  13713586.json\n",
      ".\n",
      "No program was found for task:  137f0df0.json\n",
      ".\n",
      "No program was found for task:  140c817e.json\n",
      ".\n",
      "No program was found for task:  14754a24.json\n",
      ".\n",
      "No program was found for task:  15113be4.json\n",
      ".\n",
      "No program was found for task:  15663ba9.json\n",
      ".\n",
      "No program was found for task:  15696249.json\n",
      ".\n",
      "No program was found for task:  16b78196.json\n",
      ".\n",
      "No program was found for task:  17b80ad2.json\n",
      ".\n",
      "No program was found for task:  17cae0c1.json\n",
      ".\n",
      "No program was found for task:  18419cfa.json\n",
      ".\n",
      "No program was found for task:  184a9768.json\n",
      ".\n",
      "No program was found for task:  195ba7dc.json\n",
      ".\n",
      "No program was found for task:  1990f7a8.json\n",
      ".\n",
      "No program was found for task:  19bb5feb.json\n",
      ".\n",
      "No program was found for task:  1a2e2828.json\n",
      ".\n",
      "No program was found for task:  1a6449f1.json\n",
      ".\n",
      "No program was found for task:  1acc24af.json\n",
      ".\n",
      "No program was found for task:  1c02dbbe.json\n",
      ".\n",
      "No program was found for task:  1c0d0a4b.json\n",
      ".\n",
      "No program was found for task:  1c56ad9f.json\n",
      ".\n",
      "No program was found for task:  1d0a4b61.json\n",
      ".\n",
      "No program was found for task:  1d398264.json\n",
      ".\n",
      "No program was found for task:  1da012fc.json\n",
      ".\n",
      "No program was found for task:  1e81d6f9.json\n",
      ".\n",
      "No program was found for task:  1e97544e.json\n",
      ".\n",
      "No program was found for task:  2037f2c7.json\n",
      ".\n",
      "No program was found for task:  2072aba6.json\n",
      ".\n",
      "No program was found for task:  20818e16.json\n",
      ".\n",
      "No program was found for task:  20981f0e.json\n",
      ".\n",
      "No program was found for task:  212895b5.json\n",
      ".\n",
      "No program was found for task:  21f83797.json\n",
      ".\n",
      "No program was found for task:  22a4bbc2.json\n",
      ".\n",
      "No program was found for task:  25094a63.json\n",
      ".\n",
      "No program was found for task:  2546ccf6.json\n",
      ".\n",
      "No program was found for task:  256b0a75.json\n",
      ".\n",
      "No program was found for task:  2685904e.json\n",
      ".\n",
      "No program was found for task:  2697da3f.json\n",
      ".\n",
      "No program was found for task:  2753e76c.json\n",
      ".\n",
      "No program was found for task:  27a77e38.json\n",
      ".\n",
      "No program was found for task:  27f8ce4f.json\n",
      ".\n",
      "No program was found for task:  281123b4.json\n",
      ".\n",
      "No program was found for task:  292dd178.json\n",
      ".\n",
      "No program was found for task:  29700607.json\n",
      ".\n",
      "No program was found for task:  2a5f8217.json\n",
      ".\n",
      "No program was found for task:  2b01abd0.json\n",
      ".\n",
      "No program was found for task:  2c0b0aff.json\n",
      ".\n",
      "No program was found for task:  2c737e39.json\n",
      ".\n",
      "No program was found for task:  2f0c5170.json\n",
      ".\n",
      "No program was found for task:  310f3251.json\n",
      ".\n",
      "No program was found for task:  3194b014.json\n",
      ".\n",
      "No program was found for task:  319f2597.json\n",
      ".\n",
      "No program was found for task:  31adaf00.json\n",
      ".\n",
      "No program was found for task:  31d5ba1a.json\n",
      ".\n",
      "No program was found for task:  32e9702f.json\n",
      ".\n",
      "No program was found for task:  332efdb3.json\n",
      ".\n",
      "No program was found for task:  3391f8c0.json\n",
      ".\n",
      "No program was found for task:  33b52de3.json\n",
      ".\n",
      "No program was found for task:  3490cc26.json\n",
      ".\n",
      "No program was found for task:  34b99a2b.json\n",
      ".\n",
      "No program was found for task:  351d6448.json\n",
      ".\n",
      "No program was found for task:  358ba94e.json\n",
      ".\n",
      "No program was found for task:  37d3e8b2.json\n",
      ".\n",
      "No program was found for task:  3979b1a8.json\n",
      ".\n",
      "No program was found for task:  3a301edc.json\n",
      ".\n",
      "No program was found for task:  3b4c2228.json\n",
      ".\n",
      "No program was found for task:  3d31c5b3.json\n",
      ".\n",
      "No program was found for task:  3ed85e70.json\n",
      ".\n",
      "No program was found for task:  3ee1011a.json\n",
      ".\n",
      "No program was found for task:  3f23242b.json\n",
      ".\n",
      "No program was found for task:  40f6cd08.json\n",
      ".\n",
      "No program was found for task:  414297c0.json\n",
      ".\n",
      "No program was found for task:  423a55dc.json\n"
     ]
    }
   ],
   "source": [
    "program_path = data_path/'programs/test'\n",
    "for i in testing_tasks:\n",
    "    program = save_build_model(i,test_path,program_path,5,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "program_path = data_path/'programs/test'\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "print(num_cores)\n",
    "\n",
    "programs = Parallel(n_jobs=num_cores-2)(delayed(save_build_model)\n",
    "                                        (i,test_path,program_path,100,False) for i in testing_tasks)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00576224.json',\n",
       " '009d5c81.json',\n",
       " '00dbd492.json',\n",
       " '03560426.json',\n",
       " '05a7bcf2.json',\n",
       " '0607ce86.json',\n",
       " '0692e18c.json',\n",
       " '070dd51e.json',\n",
       " '08573cc6.json',\n",
       " '0934a4d8.json',\n",
       " '09c534e7.json',\n",
       " '0a1d4ef5.json',\n",
       " '0a2355a6.json',\n",
       " '0b17323b.json',\n",
       " '0bb8deee.json',\n",
       " '0becf7df.json',\n",
       " '0c786b71.json',\n",
       " '0c9aba6e.json',\n",
       " '0d87d2a6.json',\n",
       " '0e671a1a.json',\n",
       " '0f63c0b9.json',\n",
       " '103eff5b.json',\n",
       " '11e1fe23.json',\n",
       " '12422b43.json',\n",
       " '12997ef3.json',\n",
       " '12eac192.json',\n",
       " '136b0064.json',\n",
       " '13713586.json',\n",
       " '137f0df0.json',\n",
       " '140c817e.json',\n",
       " '14754a24.json',\n",
       " '15113be4.json',\n",
       " '15663ba9.json',\n",
       " '15696249.json',\n",
       " '16b78196.json',\n",
       " '17b80ad2.json',\n",
       " '17cae0c1.json',\n",
       " '18419cfa.json',\n",
       " '184a9768.json',\n",
       " '195ba7dc.json',\n",
       " '1990f7a8.json',\n",
       " '19bb5feb.json',\n",
       " '1a2e2828.json',\n",
       " '1a6449f1.json',\n",
       " '1acc24af.json',\n",
       " '1c02dbbe.json',\n",
       " '1c0d0a4b.json',\n",
       " '1c56ad9f.json',\n",
       " '1d0a4b61.json',\n",
       " '1d398264.json',\n",
       " '1da012fc.json',\n",
       " '1e81d6f9.json',\n",
       " '1e97544e.json',\n",
       " '2037f2c7.json',\n",
       " '2072aba6.json',\n",
       " '20818e16.json',\n",
       " '20981f0e.json',\n",
       " '212895b5.json',\n",
       " '21f83797.json',\n",
       " '22a4bbc2.json',\n",
       " '25094a63.json',\n",
       " '2546ccf6.json',\n",
       " '256b0a75.json',\n",
       " '2685904e.json',\n",
       " '2697da3f.json',\n",
       " '2753e76c.json',\n",
       " '27a77e38.json',\n",
       " '27f8ce4f.json',\n",
       " '281123b4.json',\n",
       " '292dd178.json',\n",
       " '29700607.json',\n",
       " '2a5f8217.json',\n",
       " '2b01abd0.json',\n",
       " '2c0b0aff.json',\n",
       " '2c737e39.json',\n",
       " '2f0c5170.json',\n",
       " '310f3251.json',\n",
       " '3194b014.json',\n",
       " '319f2597.json',\n",
       " '31adaf00.json',\n",
       " '31d5ba1a.json',\n",
       " '32e9702f.json',\n",
       " '332efdb3.json',\n",
       " '3391f8c0.json',\n",
       " '33b52de3.json',\n",
       " '3490cc26.json',\n",
       " '34b99a2b.json',\n",
       " '351d6448.json',\n",
       " '358ba94e.json',\n",
       " '37d3e8b2.json',\n",
       " '3979b1a8.json',\n",
       " '3a301edc.json',\n",
       " '3b4c2228.json',\n",
       " '3d31c5b3.json',\n",
       " '3ed85e70.json',\n",
       " '3ee1011a.json',\n",
       " '3f23242b.json',\n",
       " '40f6cd08.json',\n",
       " '414297c0.json',\n",
       " '423a55dc.json']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "The actual search space is of size `4194304 = 4**11`. This is the total number of programs that can be build.\n",
    "It is impressive that in such a huge space a simple algorithm as this one can find a solution so fast.\n",
    "\n",
    "Nethertheless, there is a huge room for improvement.\n",
    "\n",
    "Here is a small list of ideas.\n",
    "\n",
    "* Add more fitness functions that would allow a faster convergence,\n",
    "* Keep more than one candidate per local minima found,\n",
    "* Extend the DSL to functions that allow solving more tasks,\n",
    "* Sample the candidate pool with probabilities according to the best candidates scores,\n",
    "* Add *sexual reproduction* to the programs, aka crossover.\n",
    "\n",
    "If you read so far, thanks you for staying with me all along. I hope this can help / inspire you.\n",
    "\n",
    "Please feel comfortable to comment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv(data_path / 'sample_submission.csv', index_col='output_id')\n",
    "display(submission.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flattener(pred):\n",
    "    str_pred = str([row for row in pred])\n",
    "    str_pred = str_pred.replace(', ', '')\n",
    "    str_pred = str_pred.replace('[[', '|')\n",
    "    str_pred = str_pred.replace('][', '|')\n",
    "    str_pred = str_pred.replace(']]', '|')\n",
    "    return str_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_grid = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]\n",
    "display(example_grid)\n",
    "print(flattener(example_grid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* To Do - try each with 20 iterations and then work on harder ones in a second pass\n",
    "* Add time monitoring for 9 hrs\n",
    "* return best 3 programs when nothing found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for output_id in submission.index:\n",
    "    task_id = output_id.split('_')[0]\n",
    "    pair_id = int(output_id.split('_')[1])\n",
    "    f = str(test_path / str(task_id + '.json'))\n",
    "    with open(f, 'r') as read_file:\n",
    "        task = json.load(read_file)\n",
    "        \n",
    "    program = build_model(task['train'],max_iterations=2, verbose=False)\n",
    "    if program is None:\n",
    "        print(\"No program was found for:\",f)\n",
    "        \n",
    "        # skipping over the training examples, since this will be naive predictions\n",
    "        # we will use the test input grid as the base, and make some modifications\n",
    "        data = task['test'][pair_id]['input'] # test pair input\n",
    "        # for the first guess, predict that output is unchanged\n",
    "        pred_1 = flattener(data)\n",
    "        # for the second guess, change all 0s to 5s\n",
    "        data = [[5 if i==0 else i for i in j] for j in data]\n",
    "        pred_2 = flattener(data)\n",
    "        # for the last gues, change everything to 0\n",
    "        data = [[0 for i in j] for j in data]\n",
    "        pred_3 = flattener(data)\n",
    "        pred = pred_1 + ' ' + pred_2 + ' ' + pred_3 + ' ' \n",
    "        \n",
    "    else:\n",
    "        count=count+1\n",
    "        print(\"Task:\",f,\" total:\", count,\" Found program:\", program_desc(program))\n",
    "        results = evaluate(program=program, input_image=task['test'][pair_id]['input'])\n",
    "        pred=\"\"\n",
    "        ct=min(3,len(results))\n",
    "        for i in range(ct):\n",
    "            x=results[i]\n",
    "            x[x>9] = 0 # change extra color to background if it exists\n",
    "            pred = pred + flattener(x.to_list()) + ' '\n",
    "         \n",
    "    submission.loc[output_id, 'output'] = pred\n",
    "\n",
    "submission.to_csv('submission.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!!end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
